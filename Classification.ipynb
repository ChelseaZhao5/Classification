{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 14:24:24.749043\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell\n",
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: 0.23.2\n",
      "pandas: 1.1.1\n",
      "numpy: 1.19.1\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "print('scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chelsea/Desktop/Individual'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not change this cell\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import other packages as necessary\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, log_loss, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(\"OJ.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  SpecialCH  \\\n",
       "0             237        1     1.75     1.99    0.00     0.0          0   \n",
       "1             239        1     1.75     1.99    0.00     0.3          0   \n",
       "2             245        1     1.86     2.09    0.17     0.0          0   \n",
       "3             227        1     1.69     1.69    0.00     0.0          0   \n",
       "4             228        7     1.69     1.69    0.00     0.0          0   \n",
       "\n",
       "   SpecialMM   LoyalCH Purchase  \n",
       "0          0  0.500000       CH  \n",
       "1          1  0.600000       CH  \n",
       "2          0  0.680000       CH  \n",
       "3          0  0.400000       MM  \n",
       "4          0  0.956535       CH  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see a few examples of the instances\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   WeekofPurchase  1070 non-null   int64  \n",
      " 1   StoreID         1070 non-null   int64  \n",
      " 2   PriceCH         1070 non-null   float64\n",
      " 3   PriceMM         1070 non-null   float64\n",
      " 4   DiscCH          1070 non-null   float64\n",
      " 5   DiscMM          1070 non-null   float64\n",
      " 6   SpecialCH       1070 non-null   int64  \n",
      " 7   SpecialMM       1070 non-null   int64  \n",
      " 8   LoyalCH         1070 non-null   float64\n",
      " 9   Purchase        1070 non-null   object \n",
      "dtypes: float64(5), int64(4), object(1)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>254.381308</td>\n",
       "      <td>15.558286</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>257.00</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoreID</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>3.959813</td>\n",
       "      <td>2.308984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PriceCH</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>1.867421</td>\n",
       "      <td>0.101970</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>2.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PriceMM</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>2.085411</td>\n",
       "      <td>0.134386</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>2.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiscCH</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.117474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiscMM</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.123364</td>\n",
       "      <td>0.213834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecialCH</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.147664</td>\n",
       "      <td>0.354932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecialMM</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.161682</td>\n",
       "      <td>0.368331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoyalCH</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.565782</td>\n",
       "      <td>0.307843</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.325257</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count        mean        std         min         25%     50%  \\\n",
       "WeekofPurchase  1070.0  254.381308  15.558286  227.000000  240.000000  257.00   \n",
       "StoreID         1070.0    3.959813   2.308984    1.000000    2.000000    3.00   \n",
       "PriceCH         1070.0    1.867421   0.101970    1.690000    1.790000    1.86   \n",
       "PriceMM         1070.0    2.085411   0.134386    1.690000    1.990000    2.09   \n",
       "DiscCH          1070.0    0.051860   0.117474    0.000000    0.000000    0.00   \n",
       "DiscMM          1070.0    0.123364   0.213834    0.000000    0.000000    0.00   \n",
       "SpecialCH       1070.0    0.147664   0.354932    0.000000    0.000000    0.00   \n",
       "SpecialMM       1070.0    0.161682   0.368331    0.000000    0.000000    0.00   \n",
       "LoyalCH         1070.0    0.565782   0.307843    0.000011    0.325257    0.60   \n",
       "\n",
       "                       75%         max  \n",
       "WeekofPurchase  268.000000  278.000000  \n",
       "StoreID           7.000000    7.000000  \n",
       "PriceCH           1.990000    2.090000  \n",
       "PriceMM           2.180000    2.290000  \n",
       "DiscCH            0.000000    0.500000  \n",
       "DiscMM            0.230000    0.800000  \n",
       "SpecialCH         0.000000    1.000000  \n",
       "SpecialMM         0.000000    1.000000  \n",
       "LoyalCH           0.850873    0.999947  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get the summary statistics of the dataset\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create label for each instance\n",
    "#assume an instance with CH purchased is a postitive case, and an instance with MM purchased is a negative case.\n",
    "df['PurchaseLabel']= 0\n",
    "df['PurchaseLabel'][df['Purchase']=='CH']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is missing values in the dataset\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns 'purchase' and 'PurchaseLabel' as they contain label information\n",
    "remove_cols = ['Purchase','PurchaseLabel']\n",
    "df2 = df.drop(remove_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  SpecialCH  \\\n",
       "0             237        1     1.75     1.99    0.00     0.0          0   \n",
       "1             239        1     1.75     1.99    0.00     0.3          0   \n",
       "2             245        1     1.86     2.09    0.17     0.0          0   \n",
       "3             227        1     1.69     1.69    0.00     0.0          0   \n",
       "4             228        7     1.69     1.69    0.00     0.0          0   \n",
       "\n",
       "   SpecialMM   LoyalCH  \n",
       "0          0  0.500000  \n",
       "1          1  0.600000  \n",
       "2          0  0.680000  \n",
       "3          0  0.400000  \n",
       "4          0  0.956535  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see a few examples of the instances\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tried to use MinMax method to scale numerical features, however, it doesn't work better than log transformation\n",
    "#df2['PriceMM'].hist()\n",
    "#df2['PriceMM'].max()\n",
    "#df2['PriceMM'].min()\n",
    "#b=(df2['PriceMM']-1.69)/(2.29-1.69)\n",
    "#b.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do apply log transformation on numerical features\n",
    "df2['PriceCH']=np.log(df2['PriceCH']+1)\n",
    "df2['PriceMM']=np.log(df2['PriceMM']+1)\n",
    "df2['DiscCH']=np.log(df2['DiscCH']+1)\n",
    "df2['DiscMM']=np.log(df2['DiscMM']+1)\n",
    "df2['LoyalCH']=np.log(df2['LoyalCH']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(810,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(260, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(260,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the text and train based on week of purchase \n",
    "#so the training dataset has earlier purchases and testing dataset has more recent purchases\n",
    "#this will help with reducing the issue of data leakage\n",
    "target_col = 'PurchaseLabel'\n",
    "\n",
    "y = df[target_col]\n",
    "\n",
    "train_index = df2['WeekofPurchase'] <= 268\n",
    "test_index = ~train_index\n",
    "\n",
    "X_train, X_test = df2[train_index], df2[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_leaf_nodes=5,\n",
       "                       min_samples_leaf=10, min_samples_split=10,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly selected a few hyperparameters as generate model performance baseline\n",
    "clf = DecisionTreeClassifier(random_state=42, criterion=\"entropy\",\n",
    "                             min_samples_split=10, min_samples_leaf=10, max_depth=3, max_leaf_nodes=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.762\n",
      "Accuracy   = 0.781\n",
      "Kappa      = 0.524\n",
      "Log Loss   = 7.572\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      65      28\n",
      "true:1      29     138\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70        93\n",
      "           1       0.83      0.83      0.83       167\n",
      "\n",
      "    accuracy                           0.78       260\n",
      "   macro avg       0.76      0.76      0.76       260\n",
      "weighted avg       0.78      0.78      0.78       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using the test dataset and generate the model performance measures\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.8 s, sys: 113 ms, total: 9.91 s\n",
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': [2, 10, 20],\n",
       "                         'max_features': [None, 'auto'],\n",
       "                         'max_leaf_nodes': [None, 10, 50],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [1, 5, 10]},\n",
       "             return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tunning using the grid search approach\n",
    "clf = DecisionTreeClassifier(splitter='best', class_weight=None, random_state=42)\n",
    "\n",
    "params = {'criterion': ('gini', 'entropy'), \n",
    "              'max_depth': [2, 10, 20], \n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              'max_features':[None, 'auto'], \n",
    "              'max_leaf_nodes':[None, 10, 50],\n",
    "              'min_samples_split':[1, 5, 10]}\n",
    "\n",
    "gridsearch = GridSearchCV(clf, params, scoring='f1_macro', cv=5, return_train_score=True)\n",
    "\n",
    "%time gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8032331390929995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the best hyperparameters from the grid search\n",
    "gridsearch.best_params_\n",
    "gridsearch.best_score_\n",
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-fit the model using the best hyperparameters obtained from hyperparameter tuning\n",
    "clf = DecisionTreeClassifier(random_state=42, criterion=\"gini\",\n",
    "                             min_samples_split=5, min_samples_leaf=1, max_depth=2, max_leaf_nodes=None, max_features = None)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.766\n",
      "Accuracy   = 0.788\n",
      "Kappa      = 0.532\n",
      "Log Loss   = 7.306\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      62      31\n",
      "true:1      24     143\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69        93\n",
      "           1       0.82      0.86      0.84       167\n",
      "\n",
      "    accuracy                           0.79       260\n",
      "   macro avg       0.77      0.76      0.77       260\n",
      "weighted avg       0.79      0.79      0.79       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate and display the performance measures for the model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly selected a few hyperparameters as generate model performance baseline\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.535\n",
      "Accuracy   = 0.558\n",
      "Kappa      = 0.075\n",
      "Log Loss   = 15.277\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      44      49\n",
      "true:1      66     101\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.47      0.43        93\n",
      "           1       0.67      0.60      0.64       167\n",
      "\n",
      "    accuracy                           0.56       260\n",
      "   macro avg       0.54      0.54      0.54       260\n",
      "weighted avg       0.58      0.56      0.56       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using the test dataset and generate the model performance measures\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred_knn, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred_knn)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred_knn)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred_knn)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred_knn])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred_knn, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred_knn)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.3 s, sys: 1.56 s, total: 33.8 s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
       "                         'leaf_size': [10, 20, 30],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tunning using the grid search approach\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {'weights': ('uniform', 'distance'), \n",
    "              'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "              'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "              'leaf_size':[10, 20, 30]}\n",
    "\n",
    "gridsearch = GridSearchCV(knn, params, scoring='f1_macro', cv=5, return_train_score=True)\n",
    "\n",
    "%time gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 7, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7202633747891805"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the best hyperparameters from the grid search\n",
    "gridsearch.best_params_\n",
    "gridsearch.best_score_\n",
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-fit the model using the best hyperparameters obtained from hyperparameter tuning\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=7,leaf_size= 10, algorithm ='brute', weights ='uniform')\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.559\n",
      "Accuracy   = 0.704\n",
      "Kappa      = 0.215\n",
      "Log Loss   = 10.229\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      17      76\n",
      "true:1       1     166\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.18      0.31        93\n",
      "           1       0.69      0.99      0.81       167\n",
      "\n",
      "    accuracy                           0.70       260\n",
      "   macro avg       0.82      0.59      0.56       260\n",
      "weighted avg       0.78      0.70      0.63       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate and display the performance measures for the model\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred_knn, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred_knn)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred_knn)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred_knn)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred_knn])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred_knn, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred_knn)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly selected a few hyperparameters as generate model performance baseline\n",
    "RF_clf = RandomForestClassifier(max_depth= None, criterion=\"gini\", max_features = 'auto', random_state=42)\n",
    "RF_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.787\n",
      "Accuracy   = 0.812\n",
      "Kappa      = 0.575\n",
      "Log Loss   = 6.509\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      61      32\n",
      "true:1      17     150\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71        93\n",
      "           1       0.82      0.90      0.86       167\n",
      "\n",
      "    accuracy                           0.81       260\n",
      "   macro avg       0.80      0.78      0.79       260\n",
      "weighted avg       0.81      0.81      0.81       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using the test dataset and generate the model performance measures\n",
    "y_pred_RF = RF_clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred_RF, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred_RF)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred_RF)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred_RF)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred_RF])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred_RF, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred_RF)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 44s, sys: 3.51 s, total: 4min 48s\n",
      "Wall time: 4min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'max_features': [None, 'auto'],\n",
       "                         'max_leaf_nodes': [None, 10, 50],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [1, 2, 5, 10],\n",
       "                         'n_estimators': [10, 25, 50, 100]},\n",
       "             return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tunning using the grid search approach\n",
    "clf = RandomForestClassifier(random_state=42, criterion='gini')\n",
    "params = { \n",
    "              'n_estimators':[10, 25, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              'min_samples_split':[1, 2, 5, 10],\n",
    "              'max_depth': [None, 10, 20], \n",
    "              'max_features':[None, 'auto'], \n",
    "              'max_leaf_nodes':[None, 10, 50]}\n",
    "\n",
    "gridsearch = GridSearchCV(clf, params, scoring='f1_macro', cv=5, return_train_score=True)\n",
    "\n",
    "%time gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8229326335595044"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=10, n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the best hyperparameters from the grid search\n",
    "gridsearch.best_params_\n",
    "gridsearch.best_score_\n",
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=10, n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-fit the model using the best hyperparameters obtained from hyperparameter tuning\n",
    "RF_clf = RandomForestClassifier(max_depth= None, criterion=\"gini\", max_features = 'auto',max_leaf_nodes =10,min_samples_leaf=1,min_samples_split=2,n_estimators=50, random_state=42)\n",
    "RF_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score   = 0.738\n",
      "Accuracy   = 0.777\n",
      "Kappa      = 0.482\n",
      "Log Loss   = 7.705\n",
      "\n",
      "Confusion Matrix:\n",
      "        pred:0  pred:1\n",
      "true:0      51      42\n",
      "true:1      16     151\n",
      "\n",
      "Classification  Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.55      0.64        93\n",
      "           1       0.78      0.90      0.84       167\n",
      "\n",
      "    accuracy                           0.78       260\n",
      "   macro avg       0.77      0.73      0.74       260\n",
      "weighted avg       0.77      0.78      0.77       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate and display the performance measures for the model\n",
    "y_pred_RF = RF_clf.predict(X_test)\n",
    "\n",
    "print(\"F1 Score   = {:.3f}\".format(f1_score(y_test, y_pred_RF, average=\"macro\")))\n",
    "print(\"Accuracy   = {:.3f}\".format(accuracy_score(y_test, y_pred_RF)))\n",
    "print(\"Kappa      = {:.3f}\".format(cohen_kappa_score(y_test, y_pred_RF)))\n",
    "print(\"Log Loss   = {:.3f}\".format(log_loss(y_test, y_pred_RF)))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "unique_label = np.unique([y_test, y_pred_RF])\n",
    "cmtx = pd.DataFrame(\n",
    "confusion_matrix(y_test, y_pred_RF, labels=unique_label), \n",
    "index=['true:{:}'.format(x) for x in unique_label], \n",
    "columns=['pred:{:}'.format(x) for x in unique_label])\n",
    "print(cmtx)\n",
    "print(\"\\nClassification  Report:\")\n",
    "print(classification_report(y_test, y_pred_RF)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
